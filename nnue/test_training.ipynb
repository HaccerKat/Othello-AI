{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "mLPl6Tc7sX7v"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_136bit_samples(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        raw = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "    # Unpack all bits\n",
    "    print(raw[:100])\n",
    "    print(len(raw))\n",
    "    all_bits = np.unpackbits(raw)\n",
    "\n",
    "    # Each sample = 136 bits (129 inputs + 5 unused + 2 label)\n",
    "    print(all_bits.size)\n",
    "    num_samples = all_bits.size // 136\n",
    "    all_bits = all_bits[:num_samples * 136]\n",
    "\n",
    "    # Reshape to (num_samples, 136)\n",
    "    data = all_bits.reshape((num_samples, 136))\n",
    "\n",
    "    # Slice out inputs and labels\n",
    "    inputs = data[:, :129]\n",
    "\n",
    "    labels = data[:, 134:]  # Single bit label per sample\n",
    "    labels = np.packbits(labels, axis = -1)\n",
    "    return inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "70lc6OZ6QLv6"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs_uint8, labels_uint8, transform = None):\n",
    "        self.inputs_uint8 = inputs_uint8\n",
    "        self.labels_uint8 = labels_uint8\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_uint8)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.tensor(self.inputs_uint8[idx], dtype=torch.uint8)\n",
    "        y = torch.tensor(self.labels_uint8[idx], dtype=torch.uint8)\n",
    "        X = X.float()\n",
    "        y = y.float() / 128\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1747452829369,
     "user": {
      "displayName": "Peng's Alt (Alt)",
      "userId": "04480174020089720915"
     },
     "user_tz": 420
    },
    "id": "cm2eWcJXuMKx",
    "outputId": "8cf893b4-71c6-48a8-a8df-fba577d0e6cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0 128   1  64   2   0   0   0   0   0   0   2   0\n",
      "   0   0   0   0   0 128   1  64   2   0   0   0   0   0   0   2   0   0\n",
      "   0   0   0   0 128   1  64   2   0   0   0   0   0   0   2   0   0   0\n",
      "   0   0   0 128   1  64   2   0   0   0   0   0   0   2   0   0   0   0\n",
      "   0   0 128   1  64   2   0   0   0   0   0   0   2   0   0   0   0   0\n",
      "   0 128   1  64   2   0   0   0   0   0]\n",
      "17000\n",
      "136000\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]]\n",
      "[[128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]\n",
      " [128]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# inputs, labels = load_136bit_samples('data.bin')\n",
    "inputs, labels = load_136bit_samples('data2.bin')\n",
    "print(inputs)\n",
    "print(labels)\n",
    "print(labels[:100])\n",
    "# print(inputs[:10])\n",
    "# print(len(inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1747452831357,
     "user": {
      "displayName": "Peng's Alt (Alt)",
      "userId": "04480174020089720915"
     },
     "user_tz": 420
    },
    "id": "EghMcjQtosV0",
    "outputId": "55c71344-4775-4002-8b89-e0da66c7be54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = Dataset(inputs, labels)\n",
    "training_data, test_data = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(129, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "HVxhaUJfgCgw"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "KFa6INKJgJIh"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1503560,
     "status": "ok",
     "timestamp": 1747454339092,
     "user": {
      "displayName": "Peng's Alt (Alt)",
      "userId": "04480174020089720915"
     },
     "user_tz": 420
    },
    "id": "1NaL2VuagKG6",
    "outputId": "8f8b02e0-06fb-49ee-81ee-857becd28bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.735879 [   64|  800]\n",
      "Avg Loss: 0.004118 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.004118 [   64|  800]\n",
      "Avg Loss: 0.001289 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.001289 [   64|  800]\n",
      "Avg Loss: 0.000705 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.000705 [   64|  800]\n",
      "Avg Loss: 0.000469 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.000469 [   64|  800]\n",
      "Avg Loss: 0.000345 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "  size = len(dataloader.dataset)\n",
    "  model.train()\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if batch % 2000 == 0:\n",
    "      loss, current = loss.item(), batch * batch_size + len(X)\n",
    "      print(f\"loss: {loss:>7f} [{current:>5d}|{size:>5d}]\")\n",
    "    #   print(pred)\n",
    "    #   print(loss)\n",
    "    #   print(X)\n",
    "    #   print(y)\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "  model.eval()\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  test_loss = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for X, y in dataloader:\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      pred = model(X)\n",
    "      test_loss += loss_fn(pred, y).item()\n",
    "    #   correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "  test_loss /= num_batches\n",
    "#   correct /= size\n",
    "#   print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg Loss: {test_loss:>8f} \\n\")\n",
    "  print(f\"Avg Loss: {test_loss:>8f} \\n\")\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "  return test_loss\n",
    "\n",
    "patience = 2\n",
    "epochs_without_improvement = 0\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 5\n",
    "bestNN = None\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    if test_loss < best_val_loss:\n",
    "        best_val_loss = test_loss\n",
    "        bestNN = model\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            break  # early stopping\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1747456861220,
     "user": {
      "displayName": "Peng's Alt (Alt)",
      "userId": "04480174020089720915"
     },
     "user_tz": 420
    },
    "id": "mG87LgY3wX1J",
    "outputId": "c891ce0c-281d-482c-fc0c-1e2053674fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=129, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n",
      "<class 'numpy.ndarray'>\n",
      "256\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# from collections import OrderedDict\n",
    "# for layer in model.children():\n",
    "#     if isinstance(layer, nn.Linear):\n",
    "#         print(layer.state_dict()['weight'])\n",
    "#         print(layer.state_dict()['bias'])\n",
    "\n",
    "print(model)\n",
    "# l = nn.Linear(32,1)\n",
    "# w = list(l.parameters())\n",
    "# print(w)\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "params = {k: v.cpu().numpy() for k, v in state_dict.items()}\n",
    "# print(params)\n",
    "print(type(params['linear_relu_stack.0.weight'][0]))\n",
    "print(len(params['linear_relu_stack.0.weight'])) # rows\n",
    "print(len(params['linear_relu_stack.0.weight'][0])) # columns\n",
    "\n",
    "for x in range(3):\n",
    "    y = 2 * x\n",
    "    weights = params['linear_relu_stack.' + str(y) + '.weight']\n",
    "    weights = weights.flatten()\n",
    "    # print(len(weights.tolist()))\n",
    "    # print(weights.tolist())\n",
    "    file1 = open(\"weights.txt\", \"a+\")\n",
    "    file1.write(\" \".join(str(x) for x in weights.tolist()))\n",
    "    file1.write('\\n')\n",
    "    file1.close()\n",
    "    # with open('weights.txt', 'w'):\n",
    "        # write(weights.tolist())\n",
    "\n",
    "    bias = params['linear_relu_stack.' + str(y) + '.bias']\n",
    "    file2 = open(\"biases.txt\", \"a+\")\n",
    "    file2.write(\" \".join(str(x) for x in bias.tolist()))\n",
    "    file2.write('\\n')\n",
    "    file2.close()\n",
    "    # with open('biases.txt', 'w'):\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMr6/dvfbx2pCtyX0M7+33v",
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "othello-ai",
   "language": "python",
   "name": "othello-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
