{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-08T00:03:16.324147Z",
     "start_time": "2025-06-08T00:03:16.321190Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_128bit_samples(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        raw = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "    all_bits = np.unpackbits(raw)\n",
    "    # Each sample = 128 bits (128 inputs)\n",
    "    num_samples = all_bits.size // 128\n",
    "    all_bits = all_bits[:num_samples * 128]\n",
    "\n",
    "    inputs = all_bits.reshape((num_samples, 128))\n",
    "    return inputs"
   ],
   "outputs": [],
   "execution_count": 242
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T00:03:16.339502Z",
     "start_time": "2025-06-08T00:03:16.337210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_labels(filename, n):\n",
    "    labels = torch.empty(n, 65, dtype=torch.float32)\n",
    "    with open(filename, 'r') as f:\n",
    "        for i in range(n):\n",
    "            labels[i] = torch.tensor(list(map(float, f.readline().split())), dtype=torch.float32)\n",
    "    return labels\n"
   ],
   "id": "dfb6a87ddd08a1fd",
   "outputs": [],
   "execution_count": 243
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T00:03:16.395639Z",
     "start_time": "2025-06-08T00:03:16.392916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs_uint8, policy, value, transform = None):\n",
    "        self.inputs_uint8 = inputs_uint8\n",
    "        self.policy = policy\n",
    "        self.value = value\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_uint8)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = torch.tensor(self.inputs_uint8[idx], dtype=torch.uint8).float()\n",
    "        policy = torch.tensor(self.policy[idx], dtype=torch.float32)\n",
    "        value = torch.tensor(self.value[idx], dtype=torch.float32)\n",
    "        if self.transform:\n",
    "            inputs = self.transform(inputs)\n",
    "\n",
    "        return inputs, policy, value"
   ],
   "id": "3afd711aa8a3a70a",
   "outputs": [],
   "execution_count": 244
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T00:03:16.464052Z",
     "start_time": "2025-06-08T00:03:16.449381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = load_128bit_samples(\"datasets/features.bin\")\n",
    "n = len(inputs)\n",
    "labels = load_labels(\"datasets/labels.txt\", n)\n",
    "policies = labels[:, :64]\n",
    "values = labels[:, 64:]\n",
    "dataset = Dataset(inputs, policies, values)\n",
    "training_data, test_data = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.3\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ],
   "id": "2d7a18b503104afa",
   "outputs": [],
   "execution_count": 245
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T00:03:16.509352Z",
     "start_time": "2025-06-08T00:03:16.505024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nn import NeuralNetwork, load_model\n",
    "with open('current_generation.txt', 'r') as f:\n",
    "    nn_name = f.readline()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model = load_model(NeuralNetwork, 'models/model_weights_' + nn_name + '.pth')"
   ],
   "id": "d7b79485b1850d33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "execution_count": 246
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T00:03:16.566350Z",
     "start_time": "2025-06-08T00:03:16.564168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_fn(prediction, target):\n",
    "    # could play around with the proportions later\n",
    "    # policy\n",
    "    loss = torch.nn.functional.cross_entropy(prediction[0], target[0])\n",
    "    # value\n",
    "    loss += torch.nn.functional.mse_loss(prediction[1], target[1])\n",
    "    return loss\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE, weight_decay = 1e-4)"
   ],
   "id": "4effb5a274d4e8ea",
   "outputs": [],
   "execution_count": 247
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T00:03:16.621383Z",
     "start_time": "2025-06-08T00:03:16.617871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (input, policy, value) in enumerate(dataloader):\n",
    "        input, policy, value = input.to(device), policy.to(device), value.to(device)\n",
    "        prediction = model(input)\n",
    "        # X, y = model(input)\n",
    "        # print(X)\n",
    "        # print(\"------------------------------------\")\n",
    "        # print(y)\n",
    "        loss = loss_fn(prediction, (policy, value))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if (batch + 1) % 2000 == 0:\n",
    "            loss, current = loss.item(), batch * BATCH_SIZE\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}|{size:>5d}]\")"
   ],
   "id": "d928716c15da969f",
   "outputs": [],
   "execution_count": 248
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T00:03:16.724263Z",
     "start_time": "2025-06-08T00:03:16.670595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input, policy, value in dataloader:\n",
    "            input, policy, value = input.to(device), policy.to(device), value.to(device)\n",
    "            prediction = model(input)\n",
    "            test_loss += loss_fn(prediction, (policy, value)).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    # print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg Loss: {test_loss:>8f} \\n\")\n",
    "    print(f\"Avg Loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ],
   "id": "8fe5e8ae69d9b715",
   "outputs": [],
   "execution_count": 249
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T00:03:16.801846Z",
     "start_time": "2025-06-08T00:03:16.737800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "patience = 2\n",
    "epochs_without_improvement = 0\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 5\n",
    "bestNN = None\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    if test_loss < best_val_loss:\n",
    "        best_val_loss = test_loss\n",
    "        bestNN = model\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            break  # early stopping\n",
    "\n",
    "print(\"Done!\")"
   ],
   "id": "49048ba256816837",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Avg Loss: 4.364673 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Avg Loss: 4.327793 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Avg Loss: 4.299311 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Avg Loss: 4.276863 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Avg Loss: 4.265021 \n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40000/3887164103.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  policy = torch.tensor(self.policy[idx], dtype=torch.float32)\n",
      "/tmp/ipykernel_40000/3887164103.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(self.value[idx], dtype=torch.float32)\n"
     ]
    }
   ],
   "execution_count": 250
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
